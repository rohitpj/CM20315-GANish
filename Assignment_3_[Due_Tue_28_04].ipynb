{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohitpj/CM20315-GANish/blob/main/Assignment_3_%5BDue_Tue_28_04%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 3: The GANish [Due Tue 28/04]\n",
        "\n",
        "\n",
        "|  | Assignment 3 |\n",
        "|--|--|\n",
        "| Released:  | Monday, 20th March 2023 | \n",
        "| Due: | **Tue 28/04  (week 10) [8.00pm]**\n",
        "| % of Module | 11% | \n",
        "| Marked out of | 110 Marks | \n",
        "| Submission (Where) | Moodle Upload | \n",
        "| Submission (What) | A PDF file with the report and a Jupyter Notebook with the relevant code | \n",
        "| Learning Objectives | At the end of this assignment you will have a clear understanding of how to build custom models using PyTorch |\n",
        "\n",
        "\n",
        "## Assignment Requirements\n",
        "This assignment requires you to use a (previously trained) classifier as the adversarial loss for training a generator model to generate images that appear either like a boot or a trouser. You can use the [Pytorch_Fashion_MNIST_Classifier](https://colab.research.google.com/drive/1njXVC_bAIJnkGqjqESC9TqGF2UG02ol2?usp=sharing) for this.\n",
        " \n",
        "The generator model you create must consist of at least two linear layers but can be as complicated as you want it to be. Notice, however, that the more complex the model the harder it is to train it and so you are encouraged to start with a simple model. Your model need not use CNNs. \n",
        "\n",
        "The training loop should consist of using the generator to create an (initially random) image. The classifier (Pytorch_Fashion_MNIST_Classifier) should then be used to classify this generated image. The loss of the generator is based on how \"far\" the classifier thinks the resultant image is from what you are aiming to generate. \n",
        "\n",
        "You must use this method to generate two images: \n",
        "\n",
        " 1. Trousers \n",
        " 2. A Boot\n",
        "\n",
        "Below is an example of what to expect: \n",
        "\n",
        "### A boot: \n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAKrGlDQ1BJQ0MgUHJvZmlsZQAASImVlwdQU+kWgP9700NCSUIoUkJvgnQCSAmhBVB6FZWQBAglxEBQsSEiruBaEBEBG7IgouCqFFkrotgWxQL2BVkElHWxYEPlXWAIu/vmvTfvzJw53z33/Oc//z/3zJwLAFmRKxanwooApIkyJSE+Hoyo6BgGbhDAgAJUAAPAXF6GmBUUFAAQmbF/lw/dAJq0d80nc/37+/8qSnxBBg8AKAjheH4GLw3hU4i+5IklmQCgDiB+veWZ4kluR5gmQQpE+MEkJ07zyCTHTzEaTMWEhbARpgGAJ3G5kkQASAzEz8jiJSJ5SO4IW4r4QhHCYoRd09LS+QgfR9gYiUF8pMn8zPi/5En8W854WU4uN1HG02eZErynMEOcyl35f17H/5a0VOnMHoaIkpIkviGIpSB39iAl3V/GoviFgTMs5E/FT3GS1Dd8hnkZ7JgZ5nM9/WVrUxcGzHCC0Jsjy5PJCZthQYZX6AxL0kNkeyVI2KwZ5kpm95WmhMv8SQKOLH92UljkDGcJIxbOcEZKqP9sDFvml0hDZPULRD4es/t6y86elvGX8wo5srWZSWG+srNzZ+sXiFizOTOiZLXxBZ5eszHhsnhxpodsL3FqkCxekOoj82dkhcrWZiIf5OzaINkdJnP9gmYYsEE6SEVUgnRdAPLkCUCmYEXm5EHY6eKVEmFiUiaDhXSYgMER8SzmMqwtrW0AmOzX6c/hHX2qDyH69Vlf7lMAXKInJibOzPoCkPs4NQQAcWTWZ1QHAPkcAFc38qSSrGnfVC9hABEoABpQA1pADxgDc2AN7IEzcAdewA8EgjAQDZYAHkgCaUjly8FqsB7kg0KwHewCZWA/OAQOg2PgBGgGZ8BFcAXcALfBffAY9IIB8AqMgg9gHIIgHESGqJAapA0ZQGaQNcSEXCEvKAAKgaKhOCgREkFSaDW0ASqEiqAy6CBUC/0MnYYuQtegLugh1AcNQ2+hLzAKJsE0WBM2hOfBTJgF+8Nh8GI4EV4GZ8N58Fa4FK6Ej8JN8EX4Bnwf7oVfwWMogJJD0VE6KHMUE8VGBaJiUAkoCWotqgBVgqpE1aNaUR2ou6he1AjqMxqLpqIZaHO0M9oXHY7moZeh16K3oMvQh9FN6Hb0XXQfehT9HUPGaGDMME4YDiYKk4hZjsnHlGCqMY2Yy5j7mAHMBywWS8caYR2wvthobDJ2FXYLdi+2AXsB24Xtx47hcDg1nBnOBReI4+Iycfm4PbijuPO4O7gB3Ce8HF4bb433xsfgRfhcfAn+CP4c/g5+ED9OUCQYEJwIgQQ+YSVhG6GK0Eq4RRggjBOViEZEF2IYMZm4nlhKrCdeJj4hvpOTk9OVc5QLlhPK5ciVyh2XuyrXJ/eZRCGZktikWJKUtJVUQ7pAekh6RyaTDcnu5BhyJnkruZZ8ifyM/EmeKm8hz5Hny6+TL5dvkr8j/1qBoGCgwFJYopCtUKJwUuGWwogiQdFQka3IVVyrWK54WrFHcUyJqmSlFKiUprRF6YjSNaUhCo5iSPGi8Cl5lEOUS5R+KoqqR2VTedQN1CrqZeoADUszonFoybRC2jFaJ21UmaJsqxyhvEK5XPmsci8dRTekc+ip9G30E/Ru+hcVTRWWikBls0q9yh2Vj6pzVN1VBaoFqg2q91W/qDHUvNRS1HaoNas9VUerm6oHqy9X36d+WX1kDm2O8xzenII5J+Y80oA1TDVCNFZpHNK4qTGmqaXpoynW3KN5SXNEi67lrpWsVax1TmtYm6rtqi3ULtY+r/2SocxgMVIZpYx2xqiOho6vjlTnoE6nzriukW64bq5ug+5TPaIeUy9Br1ivTW9UX1t/gf5q/Tr9RwYEA6ZBksFugw6Dj4ZGhpGGmwybDYeMVI04RtlGdUZPjMnGbsbLjCuN75lgTZgmKSZ7TW6bwqZ2pkmm5aa3zGAzezOh2V6zrrmYuY5zRXMr5/aYk8xZ5lnmdeZ9FnSLAItci2aL1/P058XM2zGvY953SzvLVMsqy8dWFCs/q1yrVqu31qbWPOty63s2ZBtvm3U2LTZvbM1sBbb7bB/YUe0W2G2ya7P7Zu9gL7Gvtx920HeIc6hw6GHSmEHMLcyrjhhHD8d1jmccPzvZO2U6nXD609ncOcX5iPPQfKP5gvlV8/tddF24Lgddel0ZrnGuB1x73XTcuG6Vbs/d9dz57tXugywTVjLrKOu1h6WHxKPR4yPbib2GfcET5enjWeDZ6UXxCvcq83rmreud6F3nPepj57PK54Ivxtffd4dvD0eTw+PUckb9HPzW+LX7k/xD/cv8nweYBkgCWhfAC/wW7FzwZKHBQtHC5kAQyAncGfg0yChoWdAvwdjgoODy4BchViGrQzpCqaFLQ4+EfgjzCNsW9jjcOFwa3hahEBEbURvxMdIzsiiyN2pe1JqoG9Hq0cLolhhcTERMdczYIq9FuxYNxNrF5sd2LzZavGLxtSXqS1KXnF2qsJS79GQcJi4y7kjcV24gt5I7Fs+Jr4gf5bF5u3mv+O78Yv6wwEVQJBhMcEkoShhKdEncmTic5JZUkjQiZAvLhG+SfZP3J39MCUypSZlIjUxtSMOnxaWdFlFEKaL2dK30FeldYjNxvrh3mdOyXctGJf6S6gwoY3FGSyYNGYxuSo2lG6V9Wa5Z5VmflkcsP7lCaYVoxc2Vpis3rxzM9s7+aRV6FW9V22qd1etX961hrTm4Flobv7Ztnd66vHUDOT45h9cT16es/zXXMrco9/2GyA2teZp5OXn9G3021uXL50vyezY5b9r/A/oH4Q+dm20279n8vYBfcL3QsrCk8OsW3pbrP1r9WPrjxNaErZ3b7Lft247dLtrevcNtx+EipaLsov6dC3Y2FTOKC4rf71q661qJbcn+3cTd0t29pQGlLXv092zf87Usqex+uUd5Q4VGxeaKj3v5e+/sc99Xv19zf+H+LweEBx4c9DnYVGlYWXIIeyjr0IuqiKqOn5g/1VarVxdWf6sR1fQeDjncXutQW3tE48i2OrhOWjd8NPbo7WOex1rqzesPNtAbCo+D49LjL3+O+7n7hP+JtpPMk/WnDE5VNFIbC5qgppVNo81Jzb0t0S1dp/1Ot7U6tzb+YvFLzRmdM+Vnlc9uO0c8l3du4nz2+bEL4gsjFxMv9rctbXt8KerSvfbg9s7L/pevXvG+cqmD1XH+qsvVM9ecrp2+zrzefMP+RtNNu5uNv9r92thp39l0y+FWy23H261d87vO3XG7c/Gu590r9zj3btxfeL+rO7z7QU9sT+8D/oOhh6kP3zzKejT+OOcJ5knBU8WnJc80nlX+ZvJbQ69979k+z76bz0OfP+7n9b/6PeP3rwN5L8gvSga1B2uHrIfODHsP33656OXAK/Gr8ZH8P5T+qHht/PrUn+5/3hyNGh14I3kz8XbLO7V3Ne9t37eNBY09+5D2YfxjwSe1T4c/Mz93fIn8Mji+/Cvua+k3k2+t3/2/P5lIm5gQcyXcqVEAhSickADA2xpkTogGgHobmR8WTc/TUwJN/wNMEfhPPD1zT4k9APWImRyL2BcAOI6oYQ6SG3meHInC3AFsYyPTmdl3ak6fFCzyx3LAYZLuVu3NAf+Q6Rn+L3X/04LJrLbgn/ZfD34HzKZdYPEAAAA4ZVhJZk1NACoAAAAIAAGHaQAEAAAAAQAAABoAAAAAAAKgAgAEAAAAAQAAABygAwAEAAAAAQAAABwAAAAAR3XWmAAABRRJREFUSA2NlmVLbVsUhu/eW4/dYneCLXYLFnYgGCgi/gR/gD9DUPSDH0RBDFCxC1Gxuzuwu/s+3qXLfT3nwl0f5h5rrDHfOeIdY25JUVHRX/88Eonk/f09ISGhsbFRXV395uZGV1f37OwsPT29rq7OyclJJpOZmJhoaGhUV1dnZGSwss/f339oaEhAYE1OTm5oaJCK7yAin56e2tjYCIjsR1NTU/P6+jozM6OsrNzc3MzKwb9+/VJUVOTr8PCwjo5OUlISckBAAIgIsvDwcH44UFtb++joaHd39/z8HM39/f3l5SWC+PAJWU9PDz3ob29vnp6e+/v7qampbW1tyMSKDUcqCHsIAZW4/4egoKAAVkREBGtZWdnd3R2al5cXwWx8fDwxMRElB4SEhJA9qb6+vrOzs7GxMeGrqKiIcI6OjqLM/sPDw8rKSjR+fn6s8fHxrBMTE6zm5ubkR01NTUtL6/HxMTQ09APU29ubQ/hM+lmFZ21t7Uv8/iU/ZCkmJkZQpaSkIFBACnt7e4tPZmZmo6OjErH631u/JIEPX2+fv15eXmNjY6IyKCjI0NBQSUlpZ2cHUCqxt7cnS0tLi4uLk0qlx8fHoul/CTk5OWyzs7Pb2NjABmFqamphYSE4OBgfSSupIO8y3mdnZ/8PIijT09MQ9vn5mUJlZWW1traipErX19coycPFxUV9fb1kcHCwpaXlh2s4DmN+KMkGMeHO+vr61taW8DU2NpbYQYS/BgYGxcXF6GW4/WMzr0IjyOvz8vKsrKxoCrpjeXk5MjKSbPr4+NB1FBlQtvCJms/NzX2SX37/H2Vy5+7urqqqyk7YA8TDwwM+Xl1d0V08uNnU1DQ5Ocn27zb9I5aohJh4BCLQuAzhoSSgMAk3WcvLy21tbQV7qTzhRYjfhZOTk6WlJeoDYwiZKUOVkZ+engAlLcKg+ASFIr9DyGtcXV0tLS0JnKai3BTayMiIMziAxsFrSk2XM19gEQQg15+9DwoWmMrDCTLzCYFIxU/z8/PEy3CqqqpipVxdXV0MSZhAosH5OI00EREtoampCV3EzfKCcB7DDTg6FXvGBQbEgctRUVGUjiam2bKzs6Xk3sPDg7wwNQRESCoPR615pUcgOYljDxljBuFEZmYm6Mw9NDCX1cHBAfdlYWFhHMWY4V0gxA+Scl5+fv7IyAg2hJKbm9vd3Y3ASOW8g4MDuEn4tAYC89TFxeWDp0wdgWisYqvgHTTiFmBccRgoUIrABwYGuDNwkOrRRWSP0rm5uYHIqf39/dvb21JIW1payjAnazSDfOCQGVA0DB0OYz5xR0HP2traiooKgsXZvr4+cCk9e8kkxtHR0R/hE+DKygrveA5dRGfBgokMXc4j3UwmdsJQqo8xGuwtLCzgGcRio7W1NfXAfUlJSYm9vT0h8IFZxcls4MEpqgFjSBZ0wUHxk2AgrPiIT7CKGUIjgMCrFF84H0S6mO7CcSzY4OvrS61RUsb29nbh7pSHQ2b6wQrYbmpqyjWOhoFNYWSFhYWrq6sknqJ3dnYSrMCtxcVFBKAhP5Ukg5j9AKWFNjc3SQ6FIXw4QK2wl8EkTCEdqaS43OM4JaScAygIvYQ1maLBCQ3XqK88Otd7b2+vcIFzvXNX/4vnzG0GJYODPUTEDCc0jLhBcYrGQw9pREThP4O8hk8Q5gNUvoU6OjrQMOHJNdTDazwlNOoGVUW4goICDuvp6RE1gYGBwnygHf4GHWftK/vHiPUAAAAASUVORK5CYII=)\n",
        "\n",
        "\n",
        "### Trousers\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "**Stretch goal**\n",
        "*This is an intentionally difficult extension of the assignment and is worth only 1% of the module* \n",
        "\n",
        "Notice that the initial output of the model will be ... erm ... \"less than ideal\". \n",
        "\n",
        "\n",
        "Experiment with improving the results. Here is one option:\n",
        " 1. Extract the output image (notice the default save function saves 20 frames - you need just one.\n",
        " 2. Add this to the classifier as a \"negative example\" -- This requires you to modify the classifier so as to allow it to load images from a folder as opposed to the automatically downloaded cache. \n",
        " 3. Retrain the classifier\n",
        " 4. Use the newly trained classifier in your loss function for the generator and generate a new set of images. \n",
        "\n",
        "## Report\n",
        "In addition the program code, you are required to submit a write up (minimum of 1 page, no maximum limit) that details the following: \n",
        "\n",
        " 1. Introduction: An introduction *briefly* discussing image generation using an adversarial classifier\n",
        " 2. Methods: A methods section that *briefly* describes your classifier \n",
        " 3. Results: A section that includes the two required images\n",
        " 4. Extensions and Results: Extensions you made to the model (if any) - this is part of the stretch goals. Be sure to also include your improved images.\n",
        " 5. Difference from GANs: Discuss how your work is different from a GAN \n",
        " \n",
        "\n",
        "\n",
        "##Marking criteria\n",
        "\n",
        "| Marking Criterion | Requirements | Weight |\n",
        "|--|--|--|\n",
        "| Generator Model (Init) | Correct input dimensions | 5 | \n",
        "| Generator Model (Init) | Correct output dimensions | 5 | \n",
        "| Generator Model (Init) | Correct handling of the batch size | 5 | \n",
        "| Generator Model (Init) | Consisting of at least TWO layers (and activation functions as relevant) \t| 5  |\n",
        "| Generator Model (Forward) | The correct reshaping of the output from the ANN before returning an \"image\". | 5 |\n",
        "| **Generator Model** | **[Total Marks, sum of above]** | **25** | \n",
        "| Training Loop | Choice of Loss | 10 |\n",
        "| Training Loop | Forward step | 10 |\n",
        "| Training Loop | Predict the category using the discriminator | 5 |\n",
        "| Training Loop | Calculation of the loss | 5 |\n",
        "| Training Loop | Correct automatic gradient calculation | 5 |\n",
        "| Training Loop | Correct updating of the Generator's parameters | 5 |\n",
        "| **The Training Loop** | **[Total Marks, sum of above]** | **40** | \n",
        "| **Final output** | **Trousers (5) and Boots (5)** | **10** | \n",
        "| Stretch Goal | Methods explored | 8 | \n",
        "| Stretch Goal | Results | 2 | \n",
        "| **Stretch Goal** | **[Total Marks, sum of above]** | **10** |\n",
        "| Report | Introduction | 5 | \n",
        "| Report | Methods | 5 | \n",
        "| Report | Results | 5 | \n",
        "| Report | Extensions and Results (Not attempting stretch goals will not be penalised twice) | 0 | \n",
        "| Report | Difference from GANs | 5 |\n",
        "| Report | Overall structure, formatting, references and coherence of report | 5 | \n",
        "| Report | **[Total Marks, sum of above]** | **25** |\n",
        "\n",
        "\n",
        "## Feedback\n",
        "This assignment will be **marked manually** and you will receive written feedback on Moodle. In addition, you have the option of discussing your solutions with me in person. \n",
        "\n",
        "## Academic Integrity\n",
        "\n",
        "Your work will be checked to ensure that you have not plagiarised. For more information about the plagiarism policy at the University see: [https://library.bath.ac.uk/referencing/plagiarism](https://library.bath.ac.uk/referencing/plagiarism)\n",
        "\n",
        "Remember that published work that you refer to in your report should be clearly referenced in your text and listed in a bibliography section given at the end of your report. For more information see, [https://library.bath.ac.uk/referencing/new-to-referencing](https://library.bath.ac.uk/referencing/new-to-referencing)\n",
        "\n",
        "Your program code will be checked for plagiarism, and in addition, will be checked against your report to ensure that you understand. \n",
        "\n",
        "### Use of ChatGPT and similar Generative AI\n",
        "You are free to use any tool that is available to you, HOWEVER, you are responsible for ensuring that : \n",
        "1. What you submit does not consist of plagiarised text from around the web that a generative model reproduced. \n",
        "2. Any errors in the content will be assumed to be on account of your lack of understanding and you will be marked accordingly. So, for example, if you use ChatGPT to generate a section and there are subtle errors in the text, you will be marked down for this. \n",
        "3. You CAN use generative models as *writing support* to create a clear and linguistically sound report. In short, if you are using it as a \"smarter\" grammar checker that is fine.  \n",
        "\n",
        "## Getting Help\n",
        "1. You must NOT get help from your peers. This is an individual assignment and you are expected to complete it by yourself. \n",
        "2. You must NOT discuss this assignment with your peers -- this assignment requires you to throughly understand the to build models, but in practice very few lines of code to complete. As such you must not discuss the actual assignment with your peers. You CAN discuss the content of the lectures associated with this assignemt. \n",
        "3. If you are posting a question to the forums you must ensure that you do NOT share any associated program code. If you do need to share code, you must send me such questions by email. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lw4-0E-wg0oK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n",
        "\n",
        "**NO CHANGES REQUIRED**"
      ],
      "metadata": {
        "id": "Ac98mLiwhXoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torch, time, os, pickle\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import os, gzip, torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import scipy.misc\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "import argparse, os, torch, time, pickle"
      ],
      "metadata": {
        "id": "oZAzizszpgNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils\n",
        "\n",
        "Utils that we use in the GANish. \n",
        "\n",
        "**NO CHANGES REQUIRED**"
      ],
      "metadata": {
        "id": "sCbKbZRkpls4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_network(net):\n",
        "    num_params = 0\n",
        "    for param in net.parameters():\n",
        "        num_params += param.numel()\n",
        "    print(net)\n",
        "    print('Total number of parameters: %d' % num_params)\n",
        "\n",
        "def save_images(images, size, image_path):\n",
        "    return imsave(images, size, image_path)\n",
        "\n",
        "def imsave(images, size, path):\n",
        "    image = np.squeeze(merge(images, size))\n",
        "    image = (image * 255).astype(np.uint8)\n",
        "    return imageio.imwrite(path, image)\n",
        "\n",
        "def merge(images, size):\n",
        "    h, w = images.shape[1], images.shape[2]\n",
        "    if (images.shape[3] in (3,4)):\n",
        "        c = images.shape[3]\n",
        "        img = np.zeros((h * size[0], w * size[1], c))\n",
        "        for idx, image in enumerate(images):\n",
        "            i = idx % size[1]\n",
        "            j = idx // size[1]\n",
        "            img[j * h:j * h + h, i * w:i * w + w, :] = image\n",
        "        return img\n",
        "    elif images.shape[3]==1:\n",
        "        img = np.zeros((h * size[0], w * size[1]))\n",
        "        for idx, image in enumerate(images):\n",
        "            i = idx % size[1]\n",
        "            j = idx // size[1]\n",
        "            img[j * h:j * h + h, i * w:i * w + w] = image[:,:,0]\n",
        "        return img\n",
        "    else:\n",
        "        raise ValueError('in merge(images,size) images parameter ''must have dimensions: HxW or HxWx3 or HxWx4')\n",
        "\n",
        "\n",
        "def generate_animation(path, num):\n",
        "    images = []\n",
        "    for e in range(num):\n",
        "        img_name = path + '_epoch%03d' % (e+1) + '.png'\n",
        "        images.append(imageio.imread(img_name))\n",
        "    imageio.mimsave(path + '_generate_animation.gif', images, fps=5)\n",
        "\n",
        "\n",
        "def loss_plot(hist, path = 'Train_hist.png', model_name = ''):\n",
        "    x = range(len(hist['G_loss']))\n",
        "\n",
        "    y2 = hist['G_loss']\n",
        "\n",
        "    plt.plot(x, y2, label='G_loss')\n",
        "\n",
        "    plt.xlabel('Iter')\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "    plt.legend(loc=4)\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    path = os.path.join(path, model_name + '_loss.png')\n",
        "\n",
        "    plt.savefig(path)\n",
        "\n",
        "    plt.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "s7XcXYi8YVHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generator\n",
        "\n",
        "**CREATE THE GENERATOR HERE**\n",
        "\n",
        "**ALSO COPY OVER YOUR CLASSIFIER AND INCLUDE THE CLASSIFIER CLASS BELOW**"
      ],
      "metadata": {
        "id": "6qNDtb0ZYqOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## The generator network. \n",
        "class generator(nn.Module):\n",
        "    def __init__(self, input_dim=100, output_dim=1, input_size=32, batch_size=1):\n",
        "        super(generator, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.input_size = input_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        ## Create a simple ANN that takes as input self.input_dim has a hidden layer and returns (1 * 28 * 28 )\n",
        "        ## -- Don't forget batch size ( which is handled automatically )\n",
        "\n",
        "        \n",
        "\n",
        "    def forward(self, input):\n",
        "        x = ## Complete using what you've defined in __init__\n",
        "        ## The output is a long vector of size 1 * 28 * 28, reshape to image dimentions before return here (again, don't forget batch size). \n",
        "        x = ## Complete\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "2ufRxIaZYrVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Copy your TRAINED classifier here.\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "!cp ## <where you saved the model on your drive>  . "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbK_xJYmOcP0",
        "outputId": "9562d077-72d0-43b2-f33a-89acdf67be1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replicate the code for the classifier class. This will allow you to load the wights. \n",
        "\n"
      ],
      "metadata": {
        "id": "0VYa8KVOPFfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Discriminator\n",
        "\n",
        "**NO CHANGES REQUIRED**"
      ],
      "metadata": {
        "id": "E68WO0hGu_BE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Load it up.\n",
        "discriminator = Classifier()\n",
        "discriminator.load_state_dict(torch.load('model.pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl2UGYgBPGCJ",
        "outputId": "d879bd2d-985f-4bef-e544-caadb483c5e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Training Loop\n",
        "\n",
        "**Update to create images**"
      ],
      "metadata": {
        "id": "YwX8_SJrvGvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the main trainer class that will generate the image.\n",
        "\n",
        "class GANish(object):\n",
        "    def __init__(self, args):\n",
        "        # parameters\n",
        "        self.batch_size = args.batch_size\n",
        "        self.epoch = args.epoch\n",
        "        self.save_dir = args.save_dir\n",
        "        self.result_dir = args.result_dir\n",
        "        self.log_dir = args.log_dir\n",
        "        self.gpu_mode = args.gpu_mode\n",
        "        self.model_name = args.gan_type + '_' + str(args.batch_size)\n",
        "        self.input_size = args.input_size\n",
        "        self.z_dim = 62\n",
        "        self.gen_target= args.gen_target\n",
        "\n",
        "        ## Load a TRAINED classifier here. \n",
        "        self.D = discriminator \n",
        "\n",
        "        # networks init\n",
        "        self.G = generator(input_dim=self.z_dim, output_dim=1, input_size=self.input_size, batch_size=self.batch_size)\n",
        "        self.G_optimizer = optim.Adam(self.G.parameters(), lr=args.lrG, betas=(args.beta1, args.beta2))\n",
        "\n",
        "        if self.gpu_mode:\n",
        "            self.G.cuda()\n",
        "            self.D.cuda()\n",
        "            ## Pick a loss here. \n",
        "            self.Loss  = ## \n",
        "        else:\n",
        "            ## Same loss here but no cuda. \n",
        "            self.Loss  = ## \n",
        "\n",
        "        print('---------- Networks architecture -------------')\n",
        "        print_network(self.G)\n",
        "        print_network(self.D)\n",
        "        print('-----------------------------------------------')\n",
        "\n",
        "\n",
        "        # Fixed noise\n",
        "        ## This is the input to the generator -- you can change shape if you feel like. \n",
        "        ## Should be batch_size x z_dim\n",
        "        torch.manual_seed( 20 ) \n",
        "        self.sample_z_ = torch.rand((self.batch_size, self.z_dim))\n",
        "        if self.gpu_mode:\n",
        "            self.sample_z_ = self.sample_z_.cuda()\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        self.train_hist = {}\n",
        "        self.train_hist['G_loss'] = []\n",
        "        self.train_hist['per_epoch_time'] = []\n",
        "        self.train_hist['total_time'] = []\n",
        "\n",
        "        ## This is what we want to generate (0 to 9 in the FMNIST dataset).\n",
        "        target = # Set this to an array which defines the output class based on what you want to generate. \n",
        "        if self.gpu_mode: \n",
        "          target = target.cuda()\n",
        "\n",
        "        print('Training start!!')\n",
        "        start_time = time.time()\n",
        "        for epoch in range(self.epoch):\n",
        "            self.save()     ## Helper function will save this for you. \n",
        "            self.G.train()  ## Set the generator to \"train\". \n",
        "            epoch_start_time = time.time()\n",
        "\n",
        "            ## Create the input noise - keep this the same dimentions as above. \n",
        "            ## Should be batch_size x z_dim\n",
        "            z_ = torch.rand((self.batch_size, self.z_dim))\n",
        "            if self.gpu_mode:\n",
        "                z_ = z_.cuda()\n",
        "\n",
        "            ## -------------------------------------------------------------------------- ##\n",
        "            ##                            Add your code here                              ##\n",
        "            ## -------------------------------------------------------------------------- ##\n",
        "\n",
        "            ## Zero grad the Generator's optimizer.\n",
        "            \n",
        "\n",
        "            ## First the forward step (Generate some image).\n",
        "            G_     = # \n",
        "            ## Now predict the category using the discriminator (the classifier you have).\n",
        "            D_fake = # \n",
        "            ## The loss is how far the prediction was from what it should be \n",
        "            ## -- You have a target (defined above) based on the image you are generating. \n",
        "            ## -- D_fake is what you got as the class of the fake image.\n",
        "            G_loss = # \n",
        "\n",
        "            ## Save the loss for inspection here. Change from .item() to whatever else depending on what you are saving.\n",
        "            self.train_hist['G_loss'].append(G_loss.item())\n",
        "\n",
        "            ## Backwards on Generator (not classifier)\n",
        "            \n",
        "\n",
        "            ## Step through the optimizer on the Genrator \n",
        "\n",
        "  \n",
        "            ## -------------------------------------------------------------------------- ##\n",
        "            ##                    No changes required below this                          ##\n",
        "            ## -------------------------------------------------------------------------- ##\n",
        "          \n",
        "\n",
        "            ## Save stuff here. \n",
        "            self.train_hist['per_epoch_time'].append(time.time() - epoch_start_time)\n",
        "            with torch.no_grad():\n",
        "                ## This will save the image to the correct folder. [If this does not work, make sure self.G(self.sample_z_) is generating an image]\n",
        "                self.visualize_results((epoch+1), fix=False)\n",
        "\n",
        "        ## Some stats here. \n",
        "        self.train_hist['total_time'].append(time.time() - start_time)\n",
        "        print(\"Avg one epoch time: %.2f, total %d epochs time: %.2f\" % (np.mean(self.train_hist['per_epoch_time']),\n",
        "              self.epoch, self.train_hist['total_time'][0]))\n",
        "        print(\"Training finish!... save training results\")\n",
        "\n",
        "        ## Save both models (You don't need the discriminator, that was not updated)\n",
        "        self.save()\n",
        "\n",
        "        ## This will create a cool gif for you. \n",
        "        generate_animation(self.result_dir + '/' + self.model_name + '/' + self.model_name,  self.epoch )\n",
        "\n",
        "        ## Plot the loss [Use this to determine how much training is required]\n",
        "        loss_plot(self.train_hist, os.path.join(self.save_dir, self.model_name), self.model_name)\n",
        "\n",
        "\n",
        "\n",
        "    ## Helper functions. \n",
        "    def visualize_results(self, epoch, fix=True):\n",
        "        self.G.eval()\n",
        "        if not os.path.exists(self.result_dir + '/' + self.model_name):\n",
        "            os.makedirs(self.result_dir + '/' + self.model_name)\n",
        "\n",
        "        tot_num_samples = 20\n",
        "\n",
        "        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n",
        "\n",
        "        if fix:\n",
        "            \"\"\" fixed noise \"\"\"\n",
        "            samples = self.G(self.sample_z_)\n",
        "        else:\n",
        "            \"\"\" random noise \"\"\"\n",
        "            sample_z_ = torch.rand((self.batch_size, self.z_dim))\n",
        "            if self.gpu_mode:\n",
        "                sample_z_ = sample_z_.cuda()\n",
        "\n",
        "            samples = self.G(sample_z_)\n",
        "\n",
        "        if self.gpu_mode:\n",
        "            samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n",
        "        else:\n",
        "            samples = samples.data.numpy().transpose(0, 2, 3, 1)\n",
        "\n",
        "        samples = (samples + 1) / 2\n",
        "        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n",
        "                          self.result_dir + '/' + self.model_name + '/' + self.model_name + '_epoch%03d' % epoch + '.png')\n",
        "\n",
        "    def save(self):\n",
        "        save_dir = os.path.join(self.save_dir, self.model_name)\n",
        "\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.makedirs(save_dir)\n",
        "\n",
        "        torch.save(self.G.state_dict(), os.path.join(save_dir, self.model_name + '_G.pkl'))\n",
        "        torch.save(self.D.state_dict(), os.path.join(save_dir, self.model_name + '_D.pkl'))\n",
        "\n",
        "        with open(os.path.join(save_dir, self.model_name + '_history.pkl'), 'wb') as f:\n",
        "            pickle.dump(self.train_hist, f)\n",
        "\n",
        "    def load(self):\n",
        "        save_dir = os.path.join(self.save_dir, self.model_name)\n",
        "\n",
        "        self.G.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + '_G.pkl')))\n",
        "        self.D.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + '_D.pkl')))"
      ],
      "metadata": {
        "id": "FeNmTOiCZPWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arguments and Main\n",
        "\n",
        "In the following line, set default=1 to generate trousers. \n",
        "```python\n",
        "parser.add_argument('--gen_target', type=int, default=9)\n",
        "```\n"
      ],
      "metadata": {
        "id": "H3WT7zxdxWx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\"\"\"parsing and configuration\"\"\"\n",
        "def parse_args():\n",
        "\n",
        "    desc = \"Pytorch Generative Network PGN\"\n",
        "    parser = argparse.ArgumentParser(description=desc)\n",
        "\n",
        "    parser.add_argument('--gan_type', type=str, default='PGN',\n",
        "                        choices=['PGN'], help='The type of Network')\n",
        "    parser.add_argument('--epoch', type=int, default=30, help='The number of epochs to run')\n",
        "    parser.add_argument('--input_size', type=int, default=28, help='The size of input image')\n",
        "    parser.add_argument('--batch_size', type=int, default=64, help='The size of batch')\n",
        "    parser.add_argument('--save_dir', type=str, default='models',\n",
        "                        help='Directory name to save the model')\n",
        "    parser.add_argument('--result_dir', type=str, default='results', help='Directory name to save the generated images')\n",
        "    parser.add_argument('--log_dir', type=str, default='logs', help='Directory name to save training logs')\n",
        "    parser.add_argument('--lrG', type=float, default=0.0002)\n",
        "    parser.add_argument('--lrD', type=float, default=0.0002)\n",
        "    parser.add_argument('--beta1', type=float, default=0.5)\n",
        "    parser.add_argument('--beta2', type=float, default=0.999)\n",
        "    parser.add_argument('--gpu_mode', type=bool, default=True)\n",
        "    parser.add_argument('--benchmark_mode', type=bool, default=True)\n",
        "    parser.add_argument('--gen_target', type=int, default=9)\n",
        "\n",
        "    return check_args(parser.parse_args(args=[]))\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"checking arguments\"\"\"\n",
        "def check_args(args):\n",
        "    # --save_dir\n",
        "    if not os.path.exists(args.save_dir):\n",
        "        os.makedirs(args.save_dir)\n",
        "\n",
        "    # --result_dir\n",
        "    if not os.path.exists(args.result_dir):\n",
        "        os.makedirs(args.result_dir)\n",
        "\n",
        "    # --result_dir\n",
        "    if not os.path.exists(args.log_dir):\n",
        "        os.makedirs(args.log_dir)\n",
        "\n",
        "    # --epoch\n",
        "    try:\n",
        "        assert args.epoch >= 1\n",
        "    except:\n",
        "        print('number of epochs must be larger than or equal to one')\n",
        "\n",
        "    # --batch_size\n",
        "    try:\n",
        "        assert args.batch_size >= 1\n",
        "    except:\n",
        "        print('batch size must be larger than or equal to one')\n",
        "\n",
        "    return args\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"main\"\"\"\n",
        "def main():\n",
        "    # parse arguments\n",
        "    args = parse_args()\n",
        "    if args is None:\n",
        "        exit()\n",
        "\n",
        "    if args.benchmark_mode:\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # declare instance for GAN\n",
        "    gan = GANish(args)\n",
        "    \n",
        "    # launch the graph in a session\n",
        "    gan.train()\n",
        "    print(\" [*] Training finished!\")\n",
        "\n",
        "    # visualize learned generator\n",
        "    gan.visualize_results(args.epoch)\n",
        "    print(\" [*] Testing finished!\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH8HBPSscT3i",
        "outputId": "5cfdf5a0-80da-454d-9036-c4d783c0c45c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- Networks architecture -------------\n",
            "generator(\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=62, out_features=1024, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=1024, out_features=784, bias=True)\n",
            "    (3): ReLU()\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 868112\n",
            "Classifier(\n",
            "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=120, bias=True)\n",
            "  (fc3): Linear(in_features=120, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n",
            "Total number of parameters: 109930\n",
            "-----------------------------------------------\n",
            "training start!!\n",
            "Avg one epoch time: 0.00, total 30 epochs time: 0.47\n",
            "Training finish!... save training results\n",
            " [*] Training finished!\n",
            " [*] Testing finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output\n",
        "\n",
        "Your output image is saved to the folder: ```/content/results/PGN_64```"
      ],
      "metadata": {
        "id": "OgM9KU5nvhYX"
      }
    }
  ]
}